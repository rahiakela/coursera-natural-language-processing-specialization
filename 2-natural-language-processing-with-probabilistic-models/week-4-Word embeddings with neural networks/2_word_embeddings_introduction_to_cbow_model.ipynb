{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_word_embeddings_introduction_to_cbow_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOPOsDYb4QIFwEQESNE+9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/coursera-natural-language-processing-specialization/blob/2-natural-language-processing-with-probabilistic-models/week-4/2_word_embeddings_introduction_to_cbow_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs2ZbYfeNCvV",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings: Intro to CBOW model, activation functions and working with Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_1pTyHHNoWa",
        "colab_type": "text"
      },
      "source": [
        "In this lecture notebook you will be given an introduction to the continuous bag-of-words model, its activation functions and some considerations when working with Numpy.\n",
        "\n",
        "Let's dive into it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYOUwAZ3UFhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGjH1TShUPi7",
        "colab_type": "text"
      },
      "source": [
        "## The continuous bag-of-words model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbCnwIeqUQhH",
        "colab_type": "text"
      },
      "source": [
        "The CBOW model is based on a neural network, the architecture of which looks like the figure below, as you'll recall from the lecture.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rahiakela/img-repo/master/deeplearning.ai-NLPS/cbow_model_architecture.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP2EEbyBUslg",
        "colab_type": "text"
      },
      "source": [
        "## Activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iWDE0zBVX21",
        "colab_type": "text"
      },
      "source": [
        "Let's start by implementing the activation functions, ReLU and softmax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8KE8joWgZY",
        "colab_type": "text"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9QN7BxLWhjD",
        "colab_type": "text"
      },
      "source": [
        "ReLU is used to calculate the values of the hidden layer, in the following formulas:\n",
        "\n",
        "\\begin{align}\n",
        " \\mathbf{z_1} &= \\mathbf{W_1}\\mathbf{x} + \\mathbf{b_1}  \\tag{1} \\\\\n",
        " \\mathbf{h} &= \\mathrm{ReLU}(\\mathbf{z_1})  \\tag{2} \\\\\n",
        "\\end{align}\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rahiakela/img-repo/master/deeplearning.ai-NLPS/ReLU.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" />\n",
        "\n",
        "Let's fix a value for $\\mathbf{z_1}$ as a working example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrHje4S4XSXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "95330bb6-d9a8-4f2e-8955-f1c49b6059e9"
      },
      "source": [
        "# Define a random seed so all random outcomes can be reproduced\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define a 5X1 column vector using numpy\n",
        "z_1 = 10 * np.random.rand(5, 1) - 5\n",
        "z_1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.25459881],\n",
              "       [ 4.50714306],\n",
              "       [ 2.31993942],\n",
              "       [ 0.98658484],\n",
              "       [-3.4398136 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHOBUnhrYe1Q",
        "colab_type": "text"
      },
      "source": [
        "Notice that using numpy's `random.rand` function returns a numpy array filled with values taken from a uniform distribution over [0, 1). Numpy allows vectorization so each value is multiplied by 10 and then substracted 5.\n",
        "\n",
        "To get the ReLU of this vector, you want all the negative values to become zeros.\n",
        "\n",
        "First create a copy of this vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr3OVXPOXvWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create copy of vector and save it in the 'h' variable\n",
        "h = z_1.copy()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GvgSO1gYvQO",
        "colab_type": "text"
      },
      "source": [
        "Now determine which of its values are negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK1kiHywYuo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cc005e9f-b117-4ee9-9d3e-c5d1b442106b"
      },
      "source": [
        "# Determine which values met the criteria (this is possible because of vectorization)\n",
        "h < 0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVgm5fSUY5v2",
        "colab_type": "text"
      },
      "source": [
        "You can now simply set all of the values which are negative to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsiFvBG-Y11D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Slice the array or vector. This is the same as applying ReLU to it\n",
        "h[h < 0] = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ8SGT3qZcFj",
        "colab_type": "text"
      },
      "source": [
        "And that's it: you have the ReLU of $\\mathbf{z_1}$!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNMkTNXHZXq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6cddfb28-cfdf-4d9a-b446-7f55710b00a0"
      },
      "source": [
        "# Print the vector after ReLU\n",
        "h"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [4.50714306],\n",
              "       [2.31993942],\n",
              "       [0.98658484],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d_ACpLDZl0N",
        "colab_type": "text"
      },
      "source": [
        "**Now implement ReLU as a function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL_bwQ0zZf08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the 'relu' function that will include the steps previously seen\n",
        "def relu(z):\n",
        "  result = z.copy()\n",
        "  result[result < 0] = 0\n",
        "\n",
        "  return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60HB5PZZaF3T",
        "colab_type": "text"
      },
      "source": [
        "**And check that it's working.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZcupmANZyp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "341478d4-8669-4b78-a306-63413bbb0cca"
      },
      "source": [
        "# Define a new vector and save it in the 'z' variable\n",
        "z = np.array([[-1.25459881], [ 4.50714306], [ 2.31993942], [ 0.98658484], [-3.4398136 ]])\n",
        "\n",
        "# Apply ReLU to it\n",
        "relu(z)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [4.50714306],\n",
              "       [2.31993942],\n",
              "       [0.98658484],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3lxJcISaVJJ",
        "colab_type": "text"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "    array([[0.        ],\n",
        "           [4.50714306],\n",
        "           [2.31993942],\n",
        "           [0.98658484],\n",
        "           [0.        ]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJunB6D-aWYh",
        "colab_type": "text"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZWG5wJeaYiL",
        "colab_type": "text"
      },
      "source": [
        "The second activation function that you need is softmax. This function is used to calculate the values of the output layer of the neural network, using the following formulas:\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rahiakela/img-repo/master/deeplearning.ai-NLPS/softmax.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" />\n",
        "\n",
        "\\begin{align}\n",
        " \\mathbf{z_2} &= \\mathbf{W_2}\\mathbf{h} + \\mathbf{b_2}   \\tag{3} \\\\\n",
        " \\mathbf{\\hat y} &= \\mathrm{softmax}(\\mathbf{z_2})   \\tag{4} \\\\\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "To calculate softmax of a vector $\\mathbf{z}$, the $i$-th component of the resulting vector is given by:\n",
        "\n",
        "$$ \\textrm{softmax}(\\textbf{z})_i = \\frac{e^{z_i} }{\\sum\\limits_{j=1}^{V} e^{z_j} }  \\tag{5} $$\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rahiakela/img-repo/master/deeplearning.ai-NLPS/softmax-example.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" />\n",
        "\n",
        "Let's work through an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjStUlymaQZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8240efaf-b3f5-4464-efc6-92336ae8df8f"
      },
      "source": [
        "# Define a new vector and save it in the 'z' variable\n",
        "z = np.array([9, 8, 11, 10, 8.5])\n",
        "z"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9. ,  8. , 11. , 10. ,  8.5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97EtZEjXciBg",
        "colab_type": "text"
      },
      "source": [
        "You'll need to calculate the exponentials of each element, both for the numerator and for the denominator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqM8Wj8Tcf3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9d457811-3ba1-485d-93a6-bf216cedbae6"
      },
      "source": [
        "# Save exponentials of the values in a new vector\n",
        "e_z = np.exp(z)\n",
        "# Print the vector with the exponential values\n",
        "e_z"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8103.08392758,  2980.95798704, 59874.1417152 , 22026.46579481,\n",
              "        4914.7688403 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epajAbHgdaIv",
        "colab_type": "text"
      },
      "source": [
        "The denominator is equal to the sum of these exponentials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxBbGQ1Icvu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d8ebf47-fb1e-43e6-c494-9685a99d99e1"
      },
      "source": [
        "# Save the sum of the exponentials\n",
        "sum_e_z = np.sum(e_z)\n",
        "\n",
        "# sum of exponentials\n",
        "sum_e_z"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97899.41826492078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIx8cpnKeCVu",
        "colab_type": "text"
      },
      "source": [
        "And the value of the first element of $\\textrm{softmax}(\\textbf{z})$ is given by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6jYjVstdlY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5c46aea-236f-4d89-90cc-11d711d4c49b"
      },
      "source": [
        "# softmax value of the first element in the original vector\n",
        "e_z[0] / sum_e_z"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08276947985173956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y15e8MiKeQG4",
        "colab_type": "text"
      },
      "source": [
        "This is for one element. You can use numpy's vectorized operations to calculate the values of all the elements of the $\\textrm{softmax}(\\textbf{z})$ vector in one go.\n",
        "\n",
        "**Implement the softmax function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbZS4SAXeLX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the 'softmax' function that will include the steps previously seen\n",
        "def softmax(z):\n",
        "  e_z = np.exp(z)\n",
        "  sum_e_z = np.sum(e_z)\n",
        "\n",
        "  return e_z / sum_e_z"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeYGWQgReq9e",
        "colab_type": "text"
      },
      "source": [
        "**Now check that it works.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Q8NBiyeoKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea5e46ed-3ac9-4199-8a5d-f90fe26b2a0c"
      },
      "source": [
        "# softmax values for original vector\n",
        "softmax([9, 8, 11, 10, 8.5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdrEmuPe1a4",
        "colab_type": "text"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "    array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpWbg6qre2SQ",
        "colab_type": "text"
      },
      "source": [
        "Notice that the sum of all these values is equal to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IAUfb_5eyaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cafd0cab-bc5f-4674-fa25-25ee7ee42ef5"
      },
      "source": [
        "# Assert that the sum of the softmax values is equal to 1\n",
        "np.sum(softmax([9, 8, 11, 10, 8.5])) == 1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_j8mCIRfRwv",
        "colab_type": "text"
      },
      "source": [
        "## Dimensions: 1-D arrays vs 2-D column vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB_qbyRffSXY",
        "colab_type": "text"
      },
      "source": [
        "Before moving on to implement forward propagation, backpropagation, and gradient descent in the next lecture notebook, let's have a look at the dimensions of the vectors you've been handling until now.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rahiakela/img-repo/master/deeplearning.ai-NLPS/inputs-dimensions.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" />\n",
        "\n",
        "Create a vector of length $V$ filled with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azeDbDiQfIiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5b5164a-6636-4aab-97ca-8a986f2b653c"
      },
      "source": [
        "# Define V. Remember this was the size of the vocabulary in the previous lecture notebook\n",
        "V = 5\n",
        "\n",
        "# Define vector of length V filled with zeros\n",
        "X = np.zeros(V)\n",
        "X"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skZd5OM8kRZ2",
        "colab_type": "text"
      },
      "source": [
        "This is a 1-dimensional array, as revealed by the `.shape` property of the array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciBGpicGkOB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83e73a4e-328b-4397-d4b2-b3717cf19fe8"
      },
      "source": [
        "# vector's shape\n",
        "X.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIT1pMwpkZDv",
        "colab_type": "text"
      },
      "source": [
        "To perform matrix multiplication in the next steps, you actually need your column vectors to be represented as a matrix with one column. In numpy, this matrix is represented as a 2-dimensional array.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rahiakela/img-repo/master/deeplearning.ai-NLPS/batch-inputs-dimensions-vectors.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" />\n",
        "\n",
        "The easiest way to convert a 1D vector to a 2D column matrix is to set its `.shape` property to the number of rows and one column, as shown in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTF1I6FOkV5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "aa6943c9-772d-4388-e212-a4e306e18d8d"
      },
      "source": [
        "# Copy vector\n",
        "x_column_vector = X.copy()\n",
        "\n",
        "# Reshape copy of vector\n",
        "x_column_vector.shape = (V, 1)   # alternatively ... = (x_array.shape[0], 1)\n",
        "x_column_vector"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "696vQ7oBmLBF",
        "colab_type": "text"
      },
      "source": [
        "The shape of the resulting \"vector\" is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrq87GvamC5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f60b3ccf-fe9d-4a2c-8894-5e5a3bbfa245"
      },
      "source": [
        "# vector's shape\n",
        "x_column_vector.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNrdow9EmSqf",
        "colab_type": "text"
      },
      "source": [
        "So you now have a 5x1 matrix that you can use to perform standard matrix multiplication.\n",
        "\n",
        "**Congratulations on finishing this lecture notebook!** Hopefully you now have a better understanding of the activation functions used in the continuous bag-of-words model, as well as a clearer idea of how to leverage Numpy's power for these types of mathematical computations.\n",
        "\n",
        "In the next lecture notebook you will get a comprehensive dive into:\n",
        "\n",
        "- Forward propagation.\n",
        "\n",
        "- Cross-entropy loss.\n",
        "\n",
        "- Backpropagation.\n",
        "\n",
        "- Gradient descent.\n",
        "\n",
        "**See you next time!**"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-4-question-duplicates.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6t3GG6qYbnTPimcCCOH69",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/coursera-natural-language-processing-specialization/blob/3-natural-language-processing-with-sequence-models/week-4/assignment_4_question_duplicates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-5rCMm44dd",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4:  Question duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK6_N3eT5Rqa",
        "colab_type": "text"
      },
      "source": [
        "Welcome to the fourth assignment of course 3. In this assignment you will explore Siamese networks applied to natural language processing. You will further explore the fundamentals of Trax and you will be able to implement a more complicated structure using it. By completing this assignment, you will learn how to implement models with different architectures. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9bCq6zk5StV",
        "colab_type": "text"
      },
      "source": [
        "## Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfOAPZkN5Uqi",
        "colab_type": "text"
      },
      "source": [
        "- [Overview](#0)\n",
        "- [Part 1: Importing the Data](#1)\n",
        "    - [1.1 Loading in the data](#1.1)\n",
        "    - [1.2 Converting a question to a tensor](#1.2)\n",
        "    - [1.3 Understanding the iterator](#1.3)\n",
        "        - [Exercise 01](#ex01)\n",
        "- [Part 2: Defining the Siamese model](#2)\n",
        "    - [2.1 Understanding Siamese Network](#2.1)\n",
        "        - [Exercise 02](#ex02)\n",
        "    - [2.2 Hard  Negative Mining](#2.2)\n",
        "        - [Exercise 03](#ex03)\n",
        "- [Part 3: Training](#3)\n",
        "    - [3.1 Training the model](#3.1)\n",
        "        - [Exercise 04](#ex04)\n",
        "- [Part 4: Evaluation](#4)\n",
        "    - [4.1 Evaluating your siamese network](#4.1)\n",
        "    - [4.2 Classify](#4.2)\n",
        "        - [Exercise 05](#ex05)\n",
        "- [Part 5: Testing with your own questions](#5)\n",
        "    - [Exercise 06](#ex06)\n",
        "- [On Siamese networks](#6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hQkng9Z5XaZ",
        "colab_type": "text"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV8sZeFv5aZS",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, concretely you will: \n",
        "\n",
        "- Learn about Siamese networks\n",
        "- Understand how the triplet loss works\n",
        "- Understand how to evaluate accuracy\n",
        "- Use cosine similarity between the model's outputted vectors\n",
        "- Use the data generator to get batches of questions\n",
        "- Predict using your own model\n",
        "\n",
        "By now, you are familiar with trax and know how to make use of classes to define your model. We will start this homework by asking you to preprocess the data the same way you did in the previous assignments. After processing the data you will build a classifier that will allow you to identify whether to questions are the same or not. \n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deeplearning.ai-NLPS/meme.png?raw=1' width='800'/>\n",
        "\n",
        "\n",
        "You will process the data first and then pad in a similar way you have done in the previous assignment. Your model will take in the two question embeddings, run them through an LSTM, and then compare the outputs of the two sub networks using cosine similarity. Before taking a deep dive into the model, start by importing the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nseaoqKr5ke6",
        "colab_type": "text"
      },
      "source": [
        "<a name='1'></a>\n",
        "## Part 1: Importing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNiEjbfb5lqX",
        "colab_type": "text"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "### 1.1 Loading in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q932AjbW5oFO",
        "colab_type": "text"
      },
      "source": [
        "You will be using the Quora question answer dataset to build a model that could identify similar questions. This is a useful task because you don't want to have several versions of the same question posted. Several times when teaching I end up responding to similar questions on piazza, or on other community forums. This data set has been labeled for you. Run the cell below to import some of the packages you will be using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpuuMymu5rFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install trax==1.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53oVKbBj6KL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63588162-4ca3-4012-f4ef-b112233befd1"
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "from trax.fastmath import numpy as fastnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rnd\n",
        "\n",
        "# set random seeds\n",
        "trax.supervised.trainer_lib.init_random_number_generators(34)\n",
        "rnd.seed(34)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhbOKDmF6YQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}